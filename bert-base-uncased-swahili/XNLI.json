{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 1.8967540264129639,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.5706959706959707,
          "accuracy_threshold": 0.6183714270591736,
          "ap": 0.5897622420842783,
          "f1": 0.6679841897233202,
          "f1_threshold": 0.3967927098274231,
          "precision": 0.503725782414307,
          "recall": 0.9912023460410557
        },
        "dot": {
          "accuracy": 0.5765567765567765,
          "accuracy_threshold": 168.2885284423828,
          "ap": 0.5859759478642583,
          "f1": 0.6713426853707416,
          "f1_threshold": 125.19928741455078,
          "precision": 0.5098934550989346,
          "recall": 0.9824046920821115
        },
        "euclidean": {
          "accuracy": 0.5435897435897435,
          "accuracy_threshold": 14.307149887084961,
          "ap": 0.5489779192432042,
          "f1": 0.6666666666666666,
          "f1_threshold": 25.235727310180664,
          "precision": 0.5,
          "recall": 1.0
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5897622420842783,
        "manhattan": {
          "accuracy": 0.5457875457875457,
          "accuracy_threshold": 331.7451171875,
          "ap": 0.5488866699729424,
          "f1": 0.6669926650366748,
          "f1_threshold": 543.3700561523438,
          "precision": 0.5003668378576669,
          "recall": 1.0
        },
        "max": {
          "accuracy": 0.5765567765567765,
          "ap": 0.5897622420842783,
          "f1": 0.6713426853707416
        },
        "similarity": {
          "accuracy": 0.5706959706959707,
          "accuracy_threshold": 0.6183714866638184,
          "ap": 0.5897622420842783,
          "f1": 0.6679841897233202,
          "f1_threshold": 0.3967926502227783,
          "precision": 0.503725782414307,
          "recall": 0.9912023460410557
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.5743589743589743,
          "accuracy_threshold": 0.5680145025253296,
          "ap": 0.5836505713204225,
          "f1": 0.6699950074887668,
          "f1_threshold": 0.417079895734787,
          "precision": 0.5079485238455715,
          "recall": 0.9838709677419355
        },
        "dot": {
          "accuracy": 0.5706959706959707,
          "accuracy_threshold": 159.68606567382812,
          "ap": 0.5714969155326036,
          "f1": 0.6721734641197729,
          "f1_threshold": 131.80758666992188,
          "precision": 0.5187250996015936,
          "recall": 0.9545454545454546
        },
        "euclidean": {
          "accuracy": 0.5494505494505495,
          "accuracy_threshold": 16.266193389892578,
          "ap": 0.5421030692575373,
          "f1": 0.6676543209876543,
          "f1_threshold": 22.854537963867188,
          "precision": 0.5033507073715562,
          "recall": 0.9912023460410557
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5836505713204225,
        "manhattan": {
          "accuracy": 0.547985347985348,
          "accuracy_threshold": 365.4212341308594,
          "ap": 0.5423267445424189,
          "f1": 0.667017913593256,
          "f1_threshold": 437.22833251953125,
          "precision": 0.5205592105263158,
          "recall": 0.9281524926686217
        },
        "max": {
          "accuracy": 0.5743589743589743,
          "ap": 0.5836505713204225,
          "f1": 0.6721734641197729
        },
        "similarity": {
          "accuracy": 0.5743589743589743,
          "accuracy_threshold": 0.5680145025253296,
          "ap": 0.5836505713204225,
          "f1": 0.6699950074887668,
          "f1_threshold": 0.4170798659324646,
          "precision": 0.5079485238455715,
          "recall": 0.9838709677419355
        }
      }
    ]
  },
  "task_name": "XNLI"
}