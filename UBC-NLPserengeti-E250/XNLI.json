{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 1.877326488494873,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.5340659340659341,
          "accuracy_threshold": 0.9521304368972778,
          "ap": 0.5339671240629773,
          "f1": 0.6666666666666666,
          "f1_threshold": 0.8429291248321533,
          "precision": 0.5007363770250368,
          "recall": 0.9970674486803519
        },
        "dot": {
          "accuracy": 0.5230769230769231,
          "accuracy_threshold": 193.5198974609375,
          "ap": 0.5205493289372881,
          "f1": 0.6666666666666665,
          "f1_threshold": 150.60977172851562,
          "precision": 0.5014792899408284,
          "recall": 0.9941348973607038
        },
        "euclidean": {
          "accuracy": 0.5377289377289377,
          "accuracy_threshold": 4.29499626159668,
          "ap": 0.5365927008098821,
          "f1": 0.6660146699266504,
          "f1_threshold": 8.495969772338867,
          "precision": 0.4996331621423331,
          "recall": 0.998533724340176
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5413266564291824,
        "manhattan": {
          "accuracy": 0.5421245421245421,
          "accuracy_threshold": 87.672607421875,
          "ap": 0.5413266564291824,
          "f1": 0.6660146699266504,
          "f1_threshold": 172.95761108398438,
          "precision": 0.4996331621423331,
          "recall": 0.998533724340176
        },
        "max": {
          "accuracy": 0.5421245421245421,
          "ap": 0.5413266564291824,
          "f1": 0.6666666666666666
        },
        "similarity": {
          "accuracy": 0.5340659340659341,
          "accuracy_threshold": 0.9521304368972778,
          "ap": 0.5339671240629773,
          "f1": 0.6666666666666666,
          "f1_threshold": 0.8429292440414429,
          "precision": 0.5007363770250368,
          "recall": 0.9970674486803519
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.5472527472527473,
          "accuracy_threshold": 0.9454360008239746,
          "ap": 0.5620420446962499,
          "f1": 0.6669926650366748,
          "f1_threshold": 0.8230551481246948,
          "precision": 0.5003668378576669,
          "recall": 1.0
        },
        "dot": {
          "accuracy": 0.5252747252747253,
          "accuracy_threshold": 197.8800506591797,
          "ap": 0.5272662240787043,
          "f1": 0.6666666666666666,
          "f1_threshold": 139.30113220214844,
          "precision": 0.5,
          "recall": 1.0
        },
        "euclidean": {
          "accuracy": 0.5531135531135531,
          "accuracy_threshold": 4.9868597984313965,
          "ap": 0.557850061269858,
          "f1": 0.6666666666666666,
          "f1_threshold": 9.107818603515625,
          "precision": 0.5,
          "recall": 1.0
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5685913379523798,
        "manhattan": {
          "accuracy": 0.5545787545787546,
          "accuracy_threshold": 95.41464233398438,
          "ap": 0.5685913379523798,
          "f1": 0.6666666666666666,
          "f1_threshold": 175.89381408691406,
          "precision": 0.5,
          "recall": 1.0
        },
        "max": {
          "accuracy": 0.5545787545787546,
          "ap": 0.5685913379523798,
          "f1": 0.6669926650366748
        },
        "similarity": {
          "accuracy": 0.5472527472527473,
          "accuracy_threshold": 0.9454361200332642,
          "ap": 0.5620420446962499,
          "f1": 0.6669926650366748,
          "f1_threshold": 0.8230553269386292,
          "precision": 0.5003668378576669,
          "recall": 1.0
        }
      }
    ]
  },
  "task_name": "XNLI"
}