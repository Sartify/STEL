{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 20.960869312286377,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.37195696032279757,
        "f1": 0.3460936934960807,
        "f1_weighted": 0.38467773053854254,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.37195696032279757,
        "scores_per_experiment": [
          {
            "accuracy": 0.3853396099529254,
            "f1": 0.36115494586641284,
            "f1_weighted": 0.3913405506290974
          },
          {
            "accuracy": 0.3776059179556153,
            "f1": 0.35252794350139394,
            "f1_weighted": 0.39224852757492734
          },
          {
            "accuracy": 0.3755884330867518,
            "f1": 0.34333459209956435,
            "f1_weighted": 0.3857643269602838
          },
          {
            "accuracy": 0.3644922663080027,
            "f1": 0.3408865060794018,
            "f1_weighted": 0.3788744797814092
          },
          {
            "accuracy": 0.37491593813046403,
            "f1": 0.3433119102003692,
            "f1_weighted": 0.39163917370069545
          },
          {
            "accuracy": 0.36348352387357097,
            "f1": 0.33972476058483453,
            "f1_weighted": 0.37706322648494867
          },
          {
            "accuracy": 0.36381977135171484,
            "f1": 0.34542263563512227,
            "f1_weighted": 0.3750769189315886
          },
          {
            "accuracy": 0.3725622057834566,
            "f1": 0.34917803726016017,
            "f1_weighted": 0.38441144999174737
          },
          {
            "accuracy": 0.3863483523873571,
            "f1": 0.3535612590428615,
            "f1_weighted": 0.4011839338865981
          },
          {
            "accuracy": 0.355413584398117,
            "f1": 0.3318343446906863,
            "f1_weighted": 0.36917471744412955
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.3644859813084112,
        "f1": 0.33726753209535526,
        "f1_weighted": 0.37614540885406195,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.3644859813084112,
        "scores_per_experiment": [
          {
            "accuracy": 0.3743236596163306,
            "f1": 0.35151724874229723,
            "f1_weighted": 0.3843846178338821
          },
          {
            "accuracy": 0.36251844564682734,
            "f1": 0.3297483281655276,
            "f1_weighted": 0.377182488751862
          },
          {
            "accuracy": 0.38121003443187407,
            "f1": 0.34371026092402096,
            "f1_weighted": 0.39606652992976493
          },
          {
            "accuracy": 0.37383177570093457,
            "f1": 0.3456469556273579,
            "f1_weighted": 0.38480463281353644
          },
          {
            "accuracy": 0.36989670437776684,
            "f1": 0.3418916928729652,
            "f1_weighted": 0.38294383928248593
          },
          {
            "accuracy": 0.3575996064928677,
            "f1": 0.3285677012328873,
            "f1_weighted": 0.37357229924247404
          },
          {
            "accuracy": 0.36153467781603543,
            "f1": 0.35158387278266673,
            "f1_weighted": 0.3730463857473858
          },
          {
            "accuracy": 0.3635022134776193,
            "f1": 0.32858064902836814,
            "f1_weighted": 0.36895504309357213
          },
          {
            "accuracy": 0.3575996064928677,
            "f1": 0.3306117527850269,
            "f1_weighted": 0.3676468758384653
          },
          {
            "accuracy": 0.3428430890309887,
            "f1": 0.32081685879243454,
            "f1_weighted": 0.3528513760071905
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}