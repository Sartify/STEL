{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 7.697950124740601,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.6666666666666666,
          "accuracy_threshold": 0.607595682144165,
          "ap": 0.7031095588208573,
          "f1": 0.7066356228172292,
          "f1_threshold": 0.5331904888153076,
          "precision": 0.5859073359073359,
          "recall": 0.8900293255131965
        },
        "dot": {
          "accuracy": 0.608058608058608,
          "accuracy_threshold": 113.45802307128906,
          "ap": 0.6369121329797302,
          "f1": 0.6848329048843188,
          "f1_threshold": 78.40604400634766,
          "precision": 0.5273159144893111,
          "recall": 0.9765395894428153
        },
        "euclidean": {
          "accuracy": 0.6725274725274726,
          "accuracy_threshold": 12.38581371307373,
          "ap": 0.6958797592001642,
          "f1": 0.7190615835777127,
          "f1_threshold": 13.123058319091797,
          "precision": 0.5992179863147605,
          "recall": 0.8988269794721407
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.7031095588208573,
        "manhattan": {
          "accuracy": 0.6695970695970695,
          "accuracy_threshold": 305.467529296875,
          "ap": 0.6947803831539552,
          "f1": 0.7177985948477752,
          "f1_threshold": 332.2999267578125,
          "precision": 0.5974658869395711,
          "recall": 0.8988269794721407
        },
        "max": {
          "accuracy": 0.6725274725274726,
          "ap": 0.7031095588208573,
          "f1": 0.7190615835777127
        },
        "similarity": {
          "accuracy": 0.6666666666666666,
          "accuracy_threshold": 0.607595682144165,
          "ap": 0.7031095588208573,
          "f1": 0.7066356228172292,
          "f1_threshold": 0.5331904888153076,
          "precision": 0.5859073359073359,
          "recall": 0.8900293255131965
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.6703296703296703,
          "accuracy_threshold": 0.6007236242294312,
          "ap": 0.7250327378004509,
          "f1": 0.7137637028014616,
          "f1_threshold": 0.5546592473983765,
          "precision": 0.6104166666666667,
          "recall": 0.8592375366568915
        },
        "dot": {
          "accuracy": 0.6249084249084249,
          "accuracy_threshold": 110.66767883300781,
          "ap": 0.6396795520576792,
          "f1": 0.6852846401718583,
          "f1_threshold": 84.60986328125,
          "precision": 0.5406779661016949,
          "recall": 0.9354838709677419
        },
        "euclidean": {
          "accuracy": 0.6754578754578755,
          "accuracy_threshold": 11.233461380004883,
          "ap": 0.7224229737886885,
          "f1": 0.7129735935706085,
          "f1_threshold": 13.279038429260254,
          "precision": 0.5858490566037736,
          "recall": 0.9105571847507331
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.7250327378004509,
        "manhattan": {
          "accuracy": 0.6754578754578755,
          "accuracy_threshold": 292.5400390625,
          "ap": 0.7219306802978378,
          "f1": 0.7120778477389812,
          "f1_threshold": 337.35528564453125,
          "precision": 0.584037558685446,
          "recall": 0.9120234604105572
        },
        "max": {
          "accuracy": 0.6754578754578755,
          "ap": 0.7250327378004509,
          "f1": 0.7137637028014616
        },
        "similarity": {
          "accuracy": 0.6703296703296703,
          "accuracy_threshold": 0.6007236242294312,
          "ap": 0.7250327378004509,
          "f1": 0.7137637028014616,
          "f1_threshold": 0.5546591281890869,
          "precision": 0.6104166666666667,
          "recall": 0.8592375366568915
        }
      }
    ]
  },
  "task_name": "XNLI"
}