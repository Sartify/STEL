{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 17.3502995967865,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.5644922663080028,
        "f1": 0.5396370461605356,
        "f1_weighted": 0.5693667124186911,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5644922663080028,
        "scores_per_experiment": [
          {
            "accuracy": 0.5911230665770006,
            "f1": 0.5605818205501749,
            "f1_weighted": 0.5911429455475863
          },
          {
            "accuracy": 0.5840618695359785,
            "f1": 0.5560423806980042,
            "f1_weighted": 0.5888793686418499
          },
          {
            "accuracy": 0.5733019502353732,
            "f1": 0.5381607244492076,
            "f1_weighted": 0.5756327880266708
          },
          {
            "accuracy": 0.5601882985877606,
            "f1": 0.5334018429800036,
            "f1_weighted": 0.5693023983170057
          },
          {
            "accuracy": 0.5682582380632145,
            "f1": 0.5487035872921363,
            "f1_weighted": 0.570723263725899
          },
          {
            "accuracy": 0.5292535305985205,
            "f1": 0.5276340612335836,
            "f1_weighted": 0.5349239022131137
          },
          {
            "accuracy": 0.5406859448554135,
            "f1": 0.5183455107491387,
            "f1_weighted": 0.5460246311884901
          },
          {
            "accuracy": 0.558843308675185,
            "f1": 0.5231857015309188,
            "f1_weighted": 0.5695242681770029
          },
          {
            "accuracy": 0.551109616677875,
            "f1": 0.5302574671019195,
            "f1_weighted": 0.5588367721952493
          },
          {
            "accuracy": 0.5880968392737055,
            "f1": 0.5600573650202697,
            "f1_weighted": 0.5886767861540428
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5775209050664044,
        "f1": 0.5567757893658071,
        "f1_weighted": 0.5811479190093128,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5775209050664044,
        "scores_per_experiment": [
          {
            "accuracy": 0.6010821446138711,
            "f1": 0.5766211693826954,
            "f1_weighted": 0.6058647744486171
          },
          {
            "accuracy": 0.5927201180521396,
            "f1": 0.5686346675168129,
            "f1_weighted": 0.598237828782812
          },
          {
            "accuracy": 0.5887850467289719,
            "f1": 0.5562299276459141,
            "f1_weighted": 0.5907405160643814
          },
          {
            "accuracy": 0.5779636005902608,
            "f1": 0.5553253027019412,
            "f1_weighted": 0.585111726135167
          },
          {
            "accuracy": 0.5823905558288244,
            "f1": 0.5658593178044714,
            "f1_weighted": 0.5832360248996586
          },
          {
            "accuracy": 0.5518937530742745,
            "f1": 0.5524215876922529,
            "f1_weighted": 0.5508561525833393
          },
          {
            "accuracy": 0.5597638957206099,
            "f1": 0.5415878690328165,
            "f1_weighted": 0.5644215427035777
          },
          {
            "accuracy": 0.5538612887358584,
            "f1": 0.5318370511563794,
            "f1_weighted": 0.5592145678121043
          },
          {
            "accuracy": 0.5789473684210527,
            "f1": 0.5587314976468207,
            "f1_weighted": 0.5854057787981657
          },
          {
            "accuracy": 0.58780127889818,
            "f1": 0.5605095030779655,
            "f1_weighted": 0.5883902778653054
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}