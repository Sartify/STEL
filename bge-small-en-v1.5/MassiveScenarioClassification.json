{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "evaluation_time": 6.518696546554565,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.4431405514458642,
        "f1": 0.4129959271428788,
        "f1_weighted": 0.42886536192175495,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4431405514458642,
        "scores_per_experiment": [
          {
            "accuracy": 0.43409549428379285,
            "f1": 0.4140635564375285,
            "f1_weighted": 0.4287829175516024
          },
          {
            "accuracy": 0.4636852723604573,
            "f1": 0.4297777692123842,
            "f1_weighted": 0.45018388636996604
          },
          {
            "accuracy": 0.45729657027572296,
            "f1": 0.4192448597678071,
            "f1_weighted": 0.43728809778175276
          },
          {
            "accuracy": 0.44552790854068597,
            "f1": 0.41329433472507016,
            "f1_weighted": 0.4418302966320616
          },
          {
            "accuracy": 0.4377942165433759,
            "f1": 0.40586718306778663,
            "f1_weighted": 0.4200595919569176
          },
          {
            "accuracy": 0.4425016812373907,
            "f1": 0.4088187205273275,
            "f1_weighted": 0.4211488886062724
          },
          {
            "accuracy": 0.4660390047074647,
            "f1": 0.4296448477323415,
            "f1_weighted": 0.4523487277840979
          },
          {
            "accuracy": 0.45292535305985204,
            "f1": 0.42523201555435336,
            "f1_weighted": 0.4392712392376684
          },
          {
            "accuracy": 0.38971082716879624,
            "f1": 0.36961423518936304,
            "f1_weighted": 0.36874076525614063
          },
          {
            "accuracy": 0.4418291862811029,
            "f1": 0.41440174921482636,
            "f1_weighted": 0.428999208041069
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4250860796851943,
        "f1": 0.3996921534794574,
        "f1_weighted": 0.4110904240860692,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4250860796851943,
        "scores_per_experiment": [
          {
            "accuracy": 0.42252828332513526,
            "f1": 0.40064609227210407,
            "f1_weighted": 0.4134892121953864
          },
          {
            "accuracy": 0.4303984259714707,
            "f1": 0.4038470567786592,
            "f1_weighted": 0.4178087671395832
          },
          {
            "accuracy": 0.43630103295622236,
            "f1": 0.40266832561248667,
            "f1_weighted": 0.41804979392378194
          },
          {
            "accuracy": 0.42597147073290703,
            "f1": 0.39288065039027903,
            "f1_weighted": 0.42293314523869796
          },
          {
            "accuracy": 0.4235120511559272,
            "f1": 0.40032740662587013,
            "f1_weighted": 0.40507103270991296
          },
          {
            "accuracy": 0.41859321200196753,
            "f1": 0.39213600255533865,
            "f1_weighted": 0.39492190348931333
          },
          {
            "accuracy": 0.4328578455484506,
            "f1": 0.409574014095324,
            "f1_weighted": 0.42315469853875753
          },
          {
            "accuracy": 0.45302508607968517,
            "f1": 0.42692508250144834,
            "f1_weighted": 0.4414020651637047
          },
          {
            "accuracy": 0.3836694540088539,
            "f1": 0.3672030528499584,
            "f1_weighted": 0.3641031497399419
          },
          {
            "accuracy": 0.42400393507132317,
            "f1": 0.40071385111310565,
            "f1_weighted": 0.4099704727216118
          }
        ]
      }
    ]
  },
  "task_name": "MassiveScenarioClassification"
}