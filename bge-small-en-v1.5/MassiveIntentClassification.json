{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 12.127743482589722,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.35326160053799593,
        "f1": 0.33846979610266537,
        "f1_weighted": 0.3412383395779756,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.35326160053799593,
        "scores_per_experiment": [
          {
            "accuracy": 0.3668459986550101,
            "f1": 0.36359887153025183,
            "f1_weighted": 0.36206679727077284
          },
          {
            "accuracy": 0.35440484196368527,
            "f1": 0.34589625373787813,
            "f1_weighted": 0.3521927092989403
          },
          {
            "accuracy": 0.33254875588433086,
            "f1": 0.3300739599823252,
            "f1_weighted": 0.32029087504688414
          },
          {
            "accuracy": 0.347679892400807,
            "f1": 0.34167501607491146,
            "f1_weighted": 0.34272664810541614
          },
          {
            "accuracy": 0.35608607935440484,
            "f1": 0.31723243467552026,
            "f1_weighted": 0.34016840969922874
          },
          {
            "accuracy": 0.36516476126429054,
            "f1": 0.3411314118875803,
            "f1_weighted": 0.35463744421300925
          },
          {
            "accuracy": 0.3389374579690652,
            "f1": 0.3337722117346225,
            "f1_weighted": 0.3204781915037364
          },
          {
            "accuracy": 0.3816408876933423,
            "f1": 0.34731114404885893,
            "f1_weighted": 0.3641991333950165
          },
          {
            "accuracy": 0.34162743779421656,
            "f1": 0.3362040678138173,
            "f1_weighted": 0.3194910422000044
          },
          {
            "accuracy": 0.347679892400807,
            "f1": 0.32780258954088837,
            "f1_weighted": 0.3361321450467473
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.3424987702902115,
        "f1": 0.3190595932889572,
        "f1_weighted": 0.3317972847788503,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.3424987702902115,
        "scores_per_experiment": [
          {
            "accuracy": 0.35809149040826366,
            "f1": 0.3438908310233327,
            "f1_weighted": 0.3573379294694825
          },
          {
            "accuracy": 0.33743236596163306,
            "f1": 0.3077751948327289,
            "f1_weighted": 0.33336962330537434
          },
          {
            "accuracy": 0.3246433841613379,
            "f1": 0.30835254920707966,
            "f1_weighted": 0.31253795995246286
          },
          {
            "accuracy": 0.3305459911460895,
            "f1": 0.3110816677791975,
            "f1_weighted": 0.3261372189990074
          },
          {
            "accuracy": 0.35514018691588783,
            "f1": 0.30960796359933823,
            "f1_weighted": 0.347371688483357
          },
          {
            "accuracy": 0.35809149040826366,
            "f1": 0.33205890872843435,
            "f1_weighted": 0.34598810242623695
          },
          {
            "accuracy": 0.3280865715691097,
            "f1": 0.31708830889702055,
            "f1_weighted": 0.309459854120008
          },
          {
            "accuracy": 0.3649778652238072,
            "f1": 0.3258297341361251,
            "f1_weighted": 0.34762321448186323
          },
          {
            "accuracy": 0.33005410723069356,
            "f1": 0.32233717393973504,
            "f1_weighted": 0.3104827927274151
          },
          {
            "accuracy": 0.337924249877029,
            "f1": 0.31257360074658,
            "f1_weighted": 0.32766446382329517
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}