{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "evaluation_time": 20.638872385025024,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.4719233355749831,
        "f1": 0.45919280253706996,
        "f1_weighted": 0.47876498525207134,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4719233355749831,
        "scores_per_experiment": [
          {
            "accuracy": 0.5181573638197714,
            "f1": 0.4962369548394084,
            "f1_weighted": 0.5223549853925369
          },
          {
            "accuracy": 0.47948890383322124,
            "f1": 0.4558331277171493,
            "f1_weighted": 0.48997279010651046
          },
          {
            "accuracy": 0.4643577673167451,
            "f1": 0.4495502110748202,
            "f1_weighted": 0.4751526665769034
          },
          {
            "accuracy": 0.46402151983860124,
            "f1": 0.44734484696524796,
            "f1_weighted": 0.47095908086217536
          },
          {
            "accuracy": 0.4754539340954943,
            "f1": 0.4567857321122905,
            "f1_weighted": 0.48366936374171915
          },
          {
            "accuracy": 0.46099529253530597,
            "f1": 0.4520062596826745,
            "f1_weighted": 0.469506675847205
          },
          {
            "accuracy": 0.4710827168796234,
            "f1": 0.46110591994182115,
            "f1_weighted": 0.48139548041604624
          },
          {
            "accuracy": 0.49058507061197043,
            "f1": 0.47299172075484097,
            "f1_weighted": 0.49031192622353786
          },
          {
            "accuracy": 0.4398117014122394,
            "f1": 0.4484558595010143,
            "f1_weighted": 0.4386462287679534
          },
          {
            "accuracy": 0.45527908540685946,
            "f1": 0.4516173927814331,
            "f1_weighted": 0.4656806545861254
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4548450565666502,
        "f1": 0.44561334300759825,
        "f1_weighted": 0.4635116132770034,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4548450565666502,
        "scores_per_experiment": [
          {
            "accuracy": 0.4717166748647319,
            "f1": 0.45624496267999043,
            "f1_weighted": 0.48032315809411574
          },
          {
            "accuracy": 0.4584358091490408,
            "f1": 0.44482189387737603,
            "f1_weighted": 0.4650826686525782
          },
          {
            "accuracy": 0.4574520413182489,
            "f1": 0.4456920840158927,
            "f1_weighted": 0.4719905545470403
          },
          {
            "accuracy": 0.4545007378258731,
            "f1": 0.4409402069079688,
            "f1_weighted": 0.4617567343418277
          },
          {
            "accuracy": 0.4692572552877521,
            "f1": 0.45766913435948364,
            "f1_weighted": 0.4756916213179202
          },
          {
            "accuracy": 0.4476143630103296,
            "f1": 0.4435920627557591,
            "f1_weighted": 0.4597488035011789
          },
          {
            "accuracy": 0.44958189867191345,
            "f1": 0.4420392506548338,
            "f1_weighted": 0.4660324596677424
          },
          {
            "accuracy": 0.4746679783571077,
            "f1": 0.4563183881690737,
            "f1_weighted": 0.47583740111934
          },
          {
            "accuracy": 0.42892277422528285,
            "f1": 0.4326312740159166,
            "f1_weighted": 0.4285966302889008
          },
          {
            "accuracy": 0.43630103295622236,
            "f1": 0.43618417263968723,
            "f1_weighted": 0.45005610123938944
          }
        ]
      }
    ]
  },
  "task_name": "MassiveScenarioClassification"
}