{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 7.658703565597534,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.5626373626373626,
          "accuracy_threshold": 0.7438638210296631,
          "ap": 0.5604971644864387,
          "f1": 0.6656891495601173,
          "f1_threshold": 0.456373929977417,
          "precision": 0.499266862170088,
          "recall": 0.998533724340176
        },
        "dot": {
          "accuracy": 0.5487179487179488,
          "accuracy_threshold": 219.7752227783203,
          "ap": 0.5488302971643559,
          "f1": 0.6660108214461387,
          "f1_threshold": 143.58642578125,
          "precision": 0.5011102886750555,
          "recall": 0.9926686217008798
        },
        "euclidean": {
          "accuracy": 0.5611721611721612,
          "accuracy_threshold": 12.155725479125977,
          "ap": 0.5619153203053111,
          "f1": 0.6656891495601173,
          "f1_threshold": 18.048860549926758,
          "precision": 0.499266862170088,
          "recall": 0.998533724340176
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5628708649113818,
        "manhattan": {
          "accuracy": 0.5611721611721612,
          "accuracy_threshold": 312.99859619140625,
          "ap": 0.5628708649113818,
          "f1": 0.6656891495601173,
          "f1_threshold": 463.2607116699219,
          "precision": 0.499266862170088,
          "recall": 0.998533724340176
        },
        "max": {
          "accuracy": 0.5626373626373626,
          "ap": 0.5628708649113818,
          "f1": 0.6660108214461387
        },
        "similarity": {
          "accuracy": 0.5626373626373626,
          "accuracy_threshold": 0.7438637614250183,
          "ap": 0.5604971644864387,
          "f1": 0.6656891495601173,
          "f1_threshold": 0.456373929977417,
          "precision": 0.499266862170088,
          "recall": 0.998533724340176
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.5802197802197803,
          "accuracy_threshold": 0.7171674966812134,
          "ap": 0.5730619556427667,
          "f1": 0.6714522363335174,
          "f1_threshold": 0.6590115427970886,
          "precision": 0.5385296722763507,
          "recall": 0.8914956011730205
        },
        "dot": {
          "accuracy": 0.567032967032967,
          "accuracy_threshold": 198.66876220703125,
          "ap": 0.5601934230952123,
          "f1": 0.6676557863501483,
          "f1_threshold": 150.14224243164062,
          "precision": 0.503731343283582,
          "recall": 0.9897360703812317
        },
        "euclidean": {
          "accuracy": 0.578021978021978,
          "accuracy_threshold": 12.550775527954102,
          "ap": 0.5741112468536609,
          "f1": 0.6673706441393875,
          "f1_threshold": 14.406293869018555,
          "precision": 0.5214521452145214,
          "recall": 0.9266862170087976
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5741112468536609,
        "manhattan": {
          "accuracy": 0.5794871794871795,
          "accuracy_threshold": 320.2565612792969,
          "ap": 0.5737860386950441,
          "f1": 0.6666666666666666,
          "f1_threshold": 414.70086669921875,
          "precision": 0.5029850746268657,
          "recall": 0.9882697947214076
        },
        "max": {
          "accuracy": 0.5802197802197803,
          "ap": 0.5741112468536609,
          "f1": 0.6714522363335174
        },
        "similarity": {
          "accuracy": 0.5802197802197803,
          "accuracy_threshold": 0.7171676158905029,
          "ap": 0.5730619556427667,
          "f1": 0.6714522363335174,
          "f1_threshold": 0.6590114831924438,
          "precision": 0.5385296722763507,
          "recall": 0.8914956011730205
        }
      }
    ]
  },
  "task_name": "XNLI"
}