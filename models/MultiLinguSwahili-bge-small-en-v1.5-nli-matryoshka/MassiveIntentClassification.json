{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 9.848537683486938,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.38002689979825155,
        "f1": 0.3569599731525633,
        "f1_weighted": 0.3596695391684446,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.38002689979825155,
        "scores_per_experiment": [
          {
            "accuracy": 0.38802958977807667,
            "f1": 0.3682646412317786,
            "f1_weighted": 0.3702212042693911
          },
          {
            "accuracy": 0.3883658372562206,
            "f1": 0.3603776195229124,
            "f1_weighted": 0.3756940308297627
          },
          {
            "accuracy": 0.3715534633490249,
            "f1": 0.3515448756995214,
            "f1_weighted": 0.3489109459881096
          },
          {
            "accuracy": 0.38029589778076667,
            "f1": 0.3747347874336094,
            "f1_weighted": 0.35855039063721494
          },
          {
            "accuracy": 0.38298587760591796,
            "f1": 0.3435193762226203,
            "f1_weighted": 0.3609704436727592
          },
          {
            "accuracy": 0.37525218560860796,
            "f1": 0.3517772337291365,
            "f1_weighted": 0.3595262965185192
          },
          {
            "accuracy": 0.3567585743106927,
            "f1": 0.34441961720690795,
            "f1_weighted": 0.33950739205406527
          },
          {
            "accuracy": 0.39172831203765973,
            "f1": 0.3602864144664328,
            "f1_weighted": 0.372471629902068
          },
          {
            "accuracy": 0.3597848016139879,
            "f1": 0.3489847664402526,
            "f1_weighted": 0.32463914641338426
          },
          {
            "accuracy": 0.4055144586415602,
            "f1": 0.36569039957246074,
            "f1_weighted": 0.3862039113991713
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.36994589276930645,
        "f1": 0.33284378803923415,
        "f1_weighted": 0.3537092010787438,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.36994589276930645,
        "scores_per_experiment": [
          {
            "accuracy": 0.367929168716183,
            "f1": 0.34079841476212175,
            "f1_weighted": 0.3521728552470837
          },
          {
            "accuracy": 0.3748155435317265,
            "f1": 0.3400479871741755,
            "f1_weighted": 0.3611332426206147
          },
          {
            "accuracy": 0.36399409739301525,
            "f1": 0.3344681697595053,
            "f1_weighted": 0.34980209949838104
          },
          {
            "accuracy": 0.35514018691588783,
            "f1": 0.32839698145399576,
            "f1_weighted": 0.33728827768571074
          },
          {
            "accuracy": 0.38022626660108216,
            "f1": 0.32985618938094946,
            "f1_weighted": 0.3643579118618503
          },
          {
            "accuracy": 0.38022626660108216,
            "f1": 0.33802320064914604,
            "f1_weighted": 0.36297199281392284
          },
          {
            "accuracy": 0.3512051155927201,
            "f1": 0.3209190057878317,
            "f1_weighted": 0.3427456778343549
          },
          {
            "accuracy": 0.39940973930152485,
            "f1": 0.34587663072994684,
            "f1_weighted": 0.3860965379894714
          },
          {
            "accuracy": 0.3512051155927201,
            "f1": 0.3327945635485726,
            "f1_weighted": 0.31932242785877707
          },
          {
            "accuracy": 0.3753074274471225,
            "f1": 0.3172567371460965,
            "f1_weighted": 0.3612009873772711
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}