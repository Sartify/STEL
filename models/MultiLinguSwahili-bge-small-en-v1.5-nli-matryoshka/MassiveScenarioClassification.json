{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "evaluation_time": 6.834622621536255,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.46839273705447215,
        "f1": 0.43797168195527314,
        "f1_weighted": 0.4493762063823878,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.46839273705447215,
        "scores_per_experiment": [
          {
            "accuracy": 0.47276395427034296,
            "f1": 0.4481216534838796,
            "f1_weighted": 0.46551008966128177
          },
          {
            "accuracy": 0.49260255548083387,
            "f1": 0.45135369024318694,
            "f1_weighted": 0.4652951807431683
          },
          {
            "accuracy": 0.4791526563550773,
            "f1": 0.446202678435148,
            "f1_weighted": 0.4562886172176462
          },
          {
            "accuracy": 0.45796906523201075,
            "f1": 0.42870968057637165,
            "f1_weighted": 0.4425460957725012
          },
          {
            "accuracy": 0.4562878278412912,
            "f1": 0.4168871407884745,
            "f1_weighted": 0.43603545688758094
          },
          {
            "accuracy": 0.4519166106254203,
            "f1": 0.4181761743620209,
            "f1_weighted": 0.4200076597283249
          },
          {
            "accuracy": 0.4899125756556826,
            "f1": 0.4606904669557109,
            "f1_weighted": 0.47595666844975276
          },
          {
            "accuracy": 0.4828513786146604,
            "f1": 0.45993756328949625,
            "f1_weighted": 0.47424144923728245
          },
          {
            "accuracy": 0.42333557498318763,
            "f1": 0.4033068671271197,
            "f1_weighted": 0.39523179452318496
          },
          {
            "accuracy": 0.47713517148621387,
            "f1": 0.4463309042913225,
            "f1_weighted": 0.4626490516031549
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4522380718150516,
        "f1": 0.42624284085996916,
        "f1_weighted": 0.43500643334276157,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4522380718150516,
        "scores_per_experiment": [
          {
            "accuracy": 0.4525332021642892,
            "f1": 0.42731756847606533,
            "f1_weighted": 0.44520874158707346
          },
          {
            "accuracy": 0.4746679783571077,
            "f1": 0.44438185085268306,
            "f1_weighted": 0.4503084104791908
          },
          {
            "accuracy": 0.45696015740285295,
            "f1": 0.4211628293416283,
            "f1_weighted": 0.43554958695388996
          },
          {
            "accuracy": 0.4471224790949336,
            "f1": 0.4225491896548902,
            "f1_weighted": 0.43553002282142983
          },
          {
            "accuracy": 0.4426955238563699,
            "f1": 0.41177851457710996,
            "f1_weighted": 0.421582824319496
          },
          {
            "accuracy": 0.4402361042793901,
            "f1": 0.4110373482200422,
            "f1_weighted": 0.41662428572290255
          },
          {
            "accuracy": 0.47614363010329563,
            "f1": 0.44898230973552017,
            "f1_weighted": 0.4672810569751404
          },
          {
            "accuracy": 0.47417609444171177,
            "f1": 0.4600072488256078,
            "f1_weighted": 0.46583363454997595
          },
          {
            "accuracy": 0.4146581406787998,
            "f1": 0.39802801231668755,
            "f1_weighted": 0.38600073097941157
          },
          {
            "accuracy": 0.44318740777176585,
            "f1": 0.4171835365994574,
            "f1_weighted": 0.4261450390391054
          }
        ]
      }
    ]
  },
  "task_name": "MassiveScenarioClassification"
}