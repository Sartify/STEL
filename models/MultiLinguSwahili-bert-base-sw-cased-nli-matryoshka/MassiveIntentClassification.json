{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 17.202699422836304,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.4613315400134499,
        "f1": 0.455760255703135,
        "f1_weighted": 0.4688411589260034,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4613315400134499,
        "scores_per_experiment": [
          {
            "accuracy": 0.4808338937457969,
            "f1": 0.4788700699398719,
            "f1_weighted": 0.4866590805104137
          },
          {
            "accuracy": 0.47007397444519167,
            "f1": 0.4528935846378752,
            "f1_weighted": 0.47671676074431174
          },
          {
            "accuracy": 0.45225285810356425,
            "f1": 0.44661890449955516,
            "f1_weighted": 0.46058528865511456
          },
          {
            "accuracy": 0.4741089441829186,
            "f1": 0.46701507850677376,
            "f1_weighted": 0.4842263490791418
          },
          {
            "accuracy": 0.44014794889038333,
            "f1": 0.4350856060703833,
            "f1_weighted": 0.4439258963858237
          },
          {
            "accuracy": 0.4428379287155346,
            "f1": 0.448233194272248,
            "f1_weighted": 0.44823815397934463
          },
          {
            "accuracy": 0.45729657027572296,
            "f1": 0.4529627170434402,
            "f1_weighted": 0.4626915911444677
          },
          {
            "accuracy": 0.4525891055817081,
            "f1": 0.44373293440495565,
            "f1_weighted": 0.4632541125522036
          },
          {
            "accuracy": 0.44317417619367855,
            "f1": 0.4476240796335702,
            "f1_weighted": 0.4526781548594809
          },
          {
            "accuracy": 0.5,
            "f1": 0.48456638802267654,
            "f1_weighted": 0.5094362013497321
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.46320708312838166,
        "f1": 0.45660859636227275,
        "f1_weighted": 0.46993482907999146,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.46320708312838166,
        "scores_per_experiment": [
          {
            "accuracy": 0.48106246925725527,
            "f1": 0.47472734440004655,
            "f1_weighted": 0.4823923309613156
          },
          {
            "accuracy": 0.4731923266109198,
            "f1": 0.4576292164950116,
            "f1_weighted": 0.4768367772839914
          },
          {
            "accuracy": 0.46040334481062467,
            "f1": 0.4539888765759748,
            "f1_weighted": 0.4715258052403144
          },
          {
            "accuracy": 0.47122479094933595,
            "f1": 0.4683524804145026,
            "f1_weighted": 0.48363017302697986
          },
          {
            "accuracy": 0.46237088047220853,
            "f1": 0.46169172148439747,
            "f1_weighted": 0.46882645387459704
          },
          {
            "accuracy": 0.46138711264141663,
            "f1": 0.4537915243375665,
            "f1_weighted": 0.4641480673126037
          },
          {
            "accuracy": 0.4436792916871618,
            "f1": 0.43900257140637466,
            "f1_weighted": 0.45124593443668515
          },
          {
            "accuracy": 0.46040334481062467,
            "f1": 0.447437221445915,
            "f1_weighted": 0.4660484570954967
          },
          {
            "accuracy": 0.43876045253320217,
            "f1": 0.44102076782800026,
            "f1_weighted": 0.4496106461102375
          },
          {
            "accuracy": 0.4795868175110674,
            "f1": 0.4684442392349388,
            "f1_weighted": 0.4850836454576926
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}