{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 39.87623119354248,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.43863483523873575,
        "f1": 0.4291403654597567,
        "f1_weighted": 0.4448693645985264,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.43863483523873575,
        "scores_per_experiment": [
          {
            "accuracy": 0.4525891055817081,
            "f1": 0.4521414403790079,
            "f1_weighted": 0.4613657907913033
          },
          {
            "accuracy": 0.44720914593140554,
            "f1": 0.43680164587756243,
            "f1_weighted": 0.455713948135066
          },
          {
            "accuracy": 0.4199731002017485,
            "f1": 0.40576028328910346,
            "f1_weighted": 0.4266270978272909
          },
          {
            "accuracy": 0.45527908540685946,
            "f1": 0.44307080102473934,
            "f1_weighted": 0.4621547542848416
          },
          {
            "accuracy": 0.44048419636852726,
            "f1": 0.42885436788542347,
            "f1_weighted": 0.44709482102198833
          },
          {
            "accuracy": 0.45527908540685946,
            "f1": 0.43451931814378,
            "f1_weighted": 0.46783326468139047
          },
          {
            "accuracy": 0.42434431741761935,
            "f1": 0.420157766883044,
            "f1_weighted": 0.4231437010347246
          },
          {
            "accuracy": 0.42165433759246806,
            "f1": 0.4162817504450607,
            "f1_weighted": 0.42813811232738946
          },
          {
            "accuracy": 0.4108944182918628,
            "f1": 0.4106103449678582,
            "f1_weighted": 0.4123161279290991
          },
          {
            "accuracy": 0.4586415601882986,
            "f1": 0.4432059357019874,
            "f1_weighted": 0.46430602795216974
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4335464830300049,
        "f1": 0.42321952501187815,
        "f1_weighted": 0.43718093038800176,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4335464830300049,
        "scores_per_experiment": [
          {
            "accuracy": 0.4515494343334973,
            "f1": 0.4461918422303868,
            "f1_weighted": 0.4535411578643048
          },
          {
            "accuracy": 0.45548450565666504,
            "f1": 0.43585464533884194,
            "f1_weighted": 0.45888241186078094
          },
          {
            "accuracy": 0.4205607476635514,
            "f1": 0.40316655154909853,
            "f1_weighted": 0.42403614824647706
          },
          {
            "accuracy": 0.4485981308411215,
            "f1": 0.4353565448466909,
            "f1_weighted": 0.4512698730257081
          },
          {
            "accuracy": 0.4353172651254304,
            "f1": 0.4335890456196487,
            "f1_weighted": 0.4449639467187376
          },
          {
            "accuracy": 0.4485981308411215,
            "f1": 0.42676915159947443,
            "f1_weighted": 0.4573197391566048
          },
          {
            "accuracy": 0.4048204623708805,
            "f1": 0.4096656560862784,
            "f1_weighted": 0.4033889925978066
          },
          {
            "accuracy": 0.4244958189867191,
            "f1": 0.4098318123944308,
            "f1_weighted": 0.42958691638647245
          },
          {
            "accuracy": 0.40924741760944416,
            "f1": 0.4072417618021944,
            "f1_weighted": 0.41212705782658166
          },
          {
            "accuracy": 0.4367929168716183,
            "f1": 0.42452823865173644,
            "f1_weighted": 0.436693060196544
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}