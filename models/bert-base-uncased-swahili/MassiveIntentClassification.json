{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 14.512837886810303,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.48301950235373237,
        "f1": 0.4537520938199213,
        "f1_weighted": 0.4893871549289628,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.48301950235373237,
        "scores_per_experiment": [
          {
            "accuracy": 0.5090786819098857,
            "f1": 0.4829206966750629,
            "f1_weighted": 0.5159021014693177
          },
          {
            "accuracy": 0.4835238735709482,
            "f1": 0.44509082389470883,
            "f1_weighted": 0.49130146095016947
          },
          {
            "accuracy": 0.48251513113651645,
            "f1": 0.45852576443020354,
            "f1_weighted": 0.48470683441538803
          },
          {
            "accuracy": 0.4899125756556826,
            "f1": 0.4472629653757795,
            "f1_weighted": 0.49415623331040176
          },
          {
            "accuracy": 0.48890383322125086,
            "f1": 0.45146735950505207,
            "f1_weighted": 0.4928918660480626
          },
          {
            "accuracy": 0.46200403496973774,
            "f1": 0.440860467474663,
            "f1_weighted": 0.46978621957336225
          },
          {
            "accuracy": 0.4761264290517821,
            "f1": 0.44843465468806054,
            "f1_weighted": 0.4867357639785146
          },
          {
            "accuracy": 0.476462676529926,
            "f1": 0.43992211480684634,
            "f1_weighted": 0.48819350745138484
          },
          {
            "accuracy": 0.47074646940147946,
            "f1": 0.4603220290184061,
            "f1_weighted": 0.47233888424088194
          },
          {
            "accuracy": 0.4909213180901143,
            "f1": 0.46271406233043094,
            "f1_weighted": 0.49785867785214505
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4877029021151008,
        "f1": 0.4637346863892387,
        "f1_weighted": 0.49250131639419986,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.4877029021151008,
        "scores_per_experiment": [
          {
            "accuracy": 0.5036891293654697,
            "f1": 0.4825349362124175,
            "f1_weighted": 0.5092169286130814
          },
          {
            "accuracy": 0.5100836202656173,
            "f1": 0.4765951915483161,
            "f1_weighted": 0.5155514801607582
          },
          {
            "accuracy": 0.47417609444171177,
            "f1": 0.4552383858645978,
            "f1_weighted": 0.47851888307057716
          },
          {
            "accuracy": 0.4963108706345303,
            "f1": 0.47328120529963963,
            "f1_weighted": 0.49817030572554016
          },
          {
            "accuracy": 0.49581898671913427,
            "f1": 0.46544980905412536,
            "f1_weighted": 0.49860918703485013
          },
          {
            "accuracy": 0.47712739793408754,
            "f1": 0.4605144494377142,
            "f1_weighted": 0.48344855445744284
          },
          {
            "accuracy": 0.4899163797343827,
            "f1": 0.4619631245721363,
            "f1_weighted": 0.4968684018931096
          },
          {
            "accuracy": 0.4751598622725037,
            "f1": 0.44432513583707256,
            "f1_weighted": 0.4835150595580444
          },
          {
            "accuracy": 0.4658140678799803,
            "f1": 0.45648131043004553,
            "f1_weighted": 0.4682438082317196
          },
          {
            "accuracy": 0.4889326119035908,
            "f1": 0.4609633156363219,
            "f1_weighted": 0.4928705551968748
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}