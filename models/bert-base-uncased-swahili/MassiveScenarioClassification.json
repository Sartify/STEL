{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "evaluation_time": 7.679742336273193,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.519334229993275,
        "f1": 0.49673633727536376,
        "f1_weighted": 0.5244879638331634,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.519334229993275,
        "scores_per_experiment": [
          {
            "accuracy": 0.5561533288500337,
            "f1": 0.5264457866152498,
            "f1_weighted": 0.560729107505625
          },
          {
            "accuracy": 0.5174848688634835,
            "f1": 0.4937306400714717,
            "f1_weighted": 0.5166655669681504
          },
          {
            "accuracy": 0.5178211163416274,
            "f1": 0.49796475173122823,
            "f1_weighted": 0.5216851401189581
          },
          {
            "accuracy": 0.5191661062542031,
            "f1": 0.4894903716268193,
            "f1_weighted": 0.5226511528387088
          },
          {
            "accuracy": 0.5332885003362475,
            "f1": 0.4986135164907633,
            "f1_weighted": 0.5401996595088626
          },
          {
            "accuracy": 0.5057162071284466,
            "f1": 0.4811834896699217,
            "f1_weighted": 0.5223615578177021
          },
          {
            "accuracy": 0.535305985205111,
            "f1": 0.5219128993580295,
            "f1_weighted": 0.5403823664260656
          },
          {
            "accuracy": 0.5063887020847344,
            "f1": 0.48722264072161514,
            "f1_weighted": 0.5135494854283125
          },
          {
            "accuracy": 0.4821788836583726,
            "f1": 0.4727762110499803,
            "f1_weighted": 0.48774551818177664
          },
          {
            "accuracy": 0.519838601210491,
            "f1": 0.49802306541855873,
            "f1_weighted": 0.5189100835374727
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5116576487948844,
        "f1": 0.4937779831760795,
        "f1_weighted": 0.5178362328845265,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5116576487948844,
        "scores_per_experiment": [
          {
            "accuracy": 0.5272995573044762,
            "f1": 0.5029387214110996,
            "f1_weighted": 0.5321749252074073
          },
          {
            "accuracy": 0.5100836202656173,
            "f1": 0.4944208957189457,
            "f1_weighted": 0.5121486064057856
          },
          {
            "accuracy": 0.514018691588785,
            "f1": 0.500813986239045,
            "f1_weighted": 0.5215278545094965
          },
          {
            "accuracy": 0.5218888342351206,
            "f1": 0.49932477784184826,
            "f1_weighted": 0.5274262647502886
          },
          {
            "accuracy": 0.5253320216428923,
            "f1": 0.5006847184021685,
            "f1_weighted": 0.5326568072055438
          },
          {
            "accuracy": 0.5066404328578455,
            "f1": 0.49055890090438925,
            "f1_weighted": 0.5219915572597092
          },
          {
            "accuracy": 0.5169699950811608,
            "f1": 0.5104001342735617,
            "f1_weighted": 0.5248078111851778
          },
          {
            "accuracy": 0.5066404328578455,
            "f1": 0.48187140040480436,
            "f1_weighted": 0.5113950147068878
          },
          {
            "accuracy": 0.4820462370880472,
            "f1": 0.4729353870676883,
            "f1_weighted": 0.4884187160426634
          },
          {
            "accuracy": 0.5056566650270536,
            "f1": 0.48383090949724417,
            "f1_weighted": 0.5058147715723038
          }
        ]
      }
    ]
  },
  "task_name": "MassiveScenarioClassification"
}