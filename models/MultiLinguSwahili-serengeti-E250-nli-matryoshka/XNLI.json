{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 1.87799072265625,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.7142857142857143,
          "accuracy_threshold": 0.5949969291687012,
          "ap": 0.7701573538510007,
          "f1": 0.7404530744336572,
          "f1_threshold": 0.5308114290237427,
          "precision": 0.6628041714947857,
          "recall": 0.8387096774193549
        },
        "dot": {
          "accuracy": 0.6967032967032967,
          "accuracy_threshold": 27.93982696533203,
          "ap": 0.723012086621925,
          "f1": 0.7429934406678592,
          "f1_threshold": 26.159208297729492,
          "precision": 0.6261306532663317,
          "recall": 0.9134897360703812
        },
        "euclidean": {
          "accuracy": 0.6637362637362637,
          "accuracy_threshold": 6.502081871032715,
          "ap": 0.7198788742424497,
          "f1": 0.6887115165336374,
          "f1_threshold": 8.17401123046875,
          "precision": 0.5634328358208955,
          "recall": 0.8856304985337243
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.7701573538510007,
        "manhattan": {
          "accuracy": 0.6666666666666666,
          "accuracy_threshold": 139.97640991210938,
          "ap": 0.7208092908462221,
          "f1": 0.6907675194660734,
          "f1_threshold": 179.94802856445312,
          "precision": 0.5564516129032258,
          "recall": 0.9105571847507331
        },
        "max": {
          "accuracy": 0.7142857142857143,
          "ap": 0.7701573538510007,
          "f1": 0.7429934406678592
        },
        "similarity": {
          "accuracy": 0.7142857142857143,
          "accuracy_threshold": 0.5949968099594116,
          "ap": 0.7701573538510007,
          "f1": 0.7404530744336572,
          "f1_threshold": 0.5308114290237427,
          "precision": 0.6628041714947857,
          "recall": 0.8387096774193549
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.7172161172161172,
          "accuracy_threshold": 0.5661691427230835,
          "ap": 0.7824929753247274,
          "f1": 0.7413366336633663,
          "f1_threshold": 0.5124359130859375,
          "precision": 0.6413276231263383,
          "recall": 0.8782991202346041
        },
        "dot": {
          "accuracy": 0.6791208791208792,
          "accuracy_threshold": 32.10807800292969,
          "ap": 0.743241957557982,
          "f1": 0.7237984944991315,
          "f1_threshold": 24.72327423095703,
          "precision": 0.5980861244019139,
          "recall": 0.9164222873900293
        },
        "euclidean": {
          "accuracy": 0.6666666666666666,
          "accuracy_threshold": 6.498682022094727,
          "ap": 0.7150361776846386,
          "f1": 0.7015772870662461,
          "f1_threshold": 7.552901268005371,
          "precision": 0.6157253599114064,
          "recall": 0.8152492668621701
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.7824929753247274,
        "manhattan": {
          "accuracy": 0.6673992673992674,
          "accuracy_threshold": 142.73269653320312,
          "ap": 0.716983148287635,
          "f1": 0.7019867549668873,
          "f1_threshold": 166.72860717773438,
          "precision": 0.5955056179775281,
          "recall": 0.8548387096774194
        },
        "max": {
          "accuracy": 0.7172161172161172,
          "ap": 0.7824929753247274,
          "f1": 0.7413366336633663
        },
        "similarity": {
          "accuracy": 0.7172161172161172,
          "accuracy_threshold": 0.5661691427230835,
          "ap": 0.7824929753247274,
          "f1": 0.7413366336633663,
          "f1_threshold": 0.5124359130859375,
          "precision": 0.6413276231263383,
          "recall": 0.8782991202346041
        }
      }
    ]
  },
  "task_name": "XNLI"
}