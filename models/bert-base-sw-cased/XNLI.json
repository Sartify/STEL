{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 2.447230577468872,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.5523809523809524,
          "accuracy_threshold": 0.7774024605751038,
          "ap": 0.5566022295763688,
          "f1": 0.6702970297029703,
          "f1_threshold": 0.49279817938804626,
          "precision": 0.5059790732436472,
          "recall": 0.9926686217008798
        },
        "dot": {
          "accuracy": 0.5413919413919414,
          "accuracy_threshold": 91.18937683105469,
          "ap": 0.5464908672978719,
          "f1": 0.6666666666666666,
          "f1_threshold": 46.03179931640625,
          "precision": 0.5029850746268657,
          "recall": 0.9882697947214076
        },
        "euclidean": {
          "accuracy": 0.5501831501831502,
          "accuracy_threshold": 7.324092864990234,
          "ap": 0.5553768541326016,
          "f1": 0.668958742632613,
          "f1_threshold": 10.935625076293945,
          "precision": 0.5029542097488922,
          "recall": 0.998533724340176
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5566022295763688,
        "manhattan": {
          "accuracy": 0.5487179487179488,
          "accuracy_threshold": 161.60284423828125,
          "ap": 0.5548046863714173,
          "f1": 0.6692874692874692,
          "f1_threshold": 238.20318603515625,
          "precision": 0.5033259423503326,
          "recall": 0.998533724340176
        },
        "max": {
          "accuracy": 0.5523809523809524,
          "ap": 0.5566022295763688,
          "f1": 0.6702970297029703
        },
        "similarity": {
          "accuracy": 0.5523809523809524,
          "accuracy_threshold": 0.7774024605751038,
          "ap": 0.5566022295763688,
          "f1": 0.6702970297029703,
          "f1_threshold": 0.4927981495857239,
          "precision": 0.5059790732436472,
          "recall": 0.9926686217008798
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.5677655677655677,
          "accuracy_threshold": 0.7433632612228394,
          "ap": 0.5819155585011591,
          "f1": 0.6666666666666666,
          "f1_threshold": 0.30989426374435425,
          "precision": 0.5,
          "recall": 1.0
        },
        "dot": {
          "accuracy": 0.5626373626373626,
          "accuracy_threshold": 85.75108337402344,
          "ap": 0.5780614673920046,
          "f1": 0.6669926650366748,
          "f1_threshold": 35.1160774230957,
          "precision": 0.5003668378576669,
          "recall": 1.0
        },
        "euclidean": {
          "accuracy": 0.5633699633699634,
          "accuracy_threshold": 7.907238006591797,
          "ap": 0.5747534603944435,
          "f1": 0.6666666666666666,
          "f1_threshold": 13.690988540649414,
          "precision": 0.5,
          "recall": 1.0
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.5819155585011591,
        "manhattan": {
          "accuracy": 0.5611721611721612,
          "accuracy_threshold": 174.63021850585938,
          "ap": 0.5754097852832845,
          "f1": 0.6666666666666666,
          "f1_threshold": 298.6817626953125,
          "precision": 0.5,
          "recall": 1.0
        },
        "max": {
          "accuracy": 0.5677655677655677,
          "ap": 0.5819155585011591,
          "f1": 0.6669926650366748
        },
        "similarity": {
          "accuracy": 0.5677655677655677,
          "accuracy_threshold": 0.7433632612228394,
          "ap": 0.5819155585011591,
          "f1": 0.6666666666666666,
          "f1_threshold": 0.3098940849304199,
          "precision": 0.5,
          "recall": 1.0
        }
      }
    ]
  },
  "task_name": "XNLI"
}