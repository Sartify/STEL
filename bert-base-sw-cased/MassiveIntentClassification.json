{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 20.337939500808716,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "accuracy": 0.36368527236045733,
        "f1": 0.35580006402292474,
        "f1_weighted": 0.3702255132546765,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.36368527236045733,
        "scores_per_experiment": [
          {
            "accuracy": 0.37794216543375925,
            "f1": 0.3770891052415845,
            "f1_weighted": 0.3869578016861856
          },
          {
            "accuracy": 0.36314727639542704,
            "f1": 0.34907350621736805,
            "f1_weighted": 0.36835276528755506
          },
          {
            "accuracy": 0.3574310692669805,
            "f1": 0.3495539623310016,
            "f1_weighted": 0.3700590584187337
          },
          {
            "accuracy": 0.3823133826496301,
            "f1": 0.37133048386093004,
            "f1_weighted": 0.3932651117154307
          },
          {
            "accuracy": 0.35642232683254876,
            "f1": 0.34549578832454136,
            "f1_weighted": 0.35953154842950524
          },
          {
            "accuracy": 0.35709482178883656,
            "f1": 0.3553568106243192,
            "f1_weighted": 0.3638072235065909
          },
          {
            "accuracy": 0.36314727639542704,
            "f1": 0.358014859795013,
            "f1_weighted": 0.3660344292264492
          },
          {
            "accuracy": 0.3628110289172831,
            "f1": 0.3515030204489058,
            "f1_weighted": 0.37448225754158015
          },
          {
            "accuracy": 0.3439811701412239,
            "f1": 0.3368189148843484,
            "f1_weighted": 0.34321877304047754
          },
          {
            "accuracy": 0.3725622057834566,
            "f1": 0.36376418850123554,
            "f1_weighted": 0.37654616369425725
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.36163305459911466,
        "f1": 0.3482455767056316,
        "f1_weighted": 0.367326360785051,
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.36163305459911466,
        "scores_per_experiment": [
          {
            "accuracy": 0.3792424987702902,
            "f1": 0.37257211564620096,
            "f1_weighted": 0.3863892097032516
          },
          {
            "accuracy": 0.3600590260698475,
            "f1": 0.34327966522843933,
            "f1_weighted": 0.3627794960337723
          },
          {
            "accuracy": 0.3649778652238072,
            "f1": 0.3638799791986944,
            "f1_weighted": 0.3754500533374638
          },
          {
            "accuracy": 0.3856369896704378,
            "f1": 0.362523284256064,
            "f1_weighted": 0.39365574680368237
          },
          {
            "accuracy": 0.3620265617314314,
            "f1": 0.3439506745978386,
            "f1_weighted": 0.3627862556422054
          },
          {
            "accuracy": 0.3585833743236596,
            "f1": 0.33913711991652956,
            "f1_weighted": 0.3688937573243721
          },
          {
            "accuracy": 0.34825381210034434,
            "f1": 0.33437913279838655,
            "f1_weighted": 0.3500295296952255
          },
          {
            "accuracy": 0.3605509099852435,
            "f1": 0.35377158174561635,
            "f1_weighted": 0.3728451238259031
          },
          {
            "accuracy": 0.34087555336940484,
            "f1": 0.32775061812070233,
            "f1_weighted": 0.33889411144855197
          },
          {
            "accuracy": 0.3561239547466798,
            "f1": 0.3412115955478444,
            "f1_weighted": 0.3615403240360819
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}