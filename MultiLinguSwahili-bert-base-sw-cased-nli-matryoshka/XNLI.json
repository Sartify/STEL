{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 2.453810691833496,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.68",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.6446886446886447,
          "accuracy_threshold": 0.4693848788738251,
          "ap": 0.6851153709237239,
          "f1": 0.7018909899888764,
          "f1_threshold": 0.3566581606864929,
          "precision": 0.5654121863799283,
          "recall": 0.9252199413489736
        },
        "dot": {
          "accuracy": 0.6175824175824176,
          "accuracy_threshold": 31.22648811340332,
          "ap": 0.6298193948071327,
          "f1": 0.6909894969596463,
          "f1_threshold": 24.284303665161133,
          "precision": 0.554569653948536,
          "recall": 0.9164222873900293
        },
        "euclidean": {
          "accuracy": 0.6732600732600733,
          "accuracy_threshold": 8.681014060974121,
          "ap": 0.6974838611987966,
          "f1": 0.7149425287356322,
          "f1_threshold": 9.53197956085205,
          "precision": 0.5879017013232514,
          "recall": 0.9120234604105572
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.6974838611987966,
        "manhattan": {
          "accuracy": 0.6703296703296703,
          "accuracy_threshold": 190.65447998046875,
          "ap": 0.6972818649976036,
          "f1": 0.7169811320754718,
          "f1_threshold": 210.39405822753906,
          "precision": 0.5876288659793815,
          "recall": 0.9193548387096774
        },
        "max": {
          "accuracy": 0.6732600732600733,
          "ap": 0.6974838611987966,
          "f1": 0.7169811320754718
        },
        "similarity": {
          "accuracy": 0.6446886446886447,
          "accuracy_threshold": 0.46938496828079224,
          "ap": 0.6851147181448498,
          "f1": 0.7018909899888764,
          "f1_threshold": 0.35665827989578247,
          "precision": 0.5654121863799283,
          "recall": 0.9252199413489736
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.6542124542124542,
          "accuracy_threshold": 0.5331772565841675,
          "ap": 0.7019663215073155,
          "f1": 0.701065619742008,
          "f1_threshold": 0.3683116137981415,
          "precision": 0.5676657584014533,
          "recall": 0.9164222873900293
        },
        "dot": {
          "accuracy": 0.6190476190476191,
          "accuracy_threshold": 31.646160125732422,
          "ap": 0.6390842807906112,
          "f1": 0.6882766072393299,
          "f1_threshold": 23.418333053588867,
          "precision": 0.5449101796407185,
          "recall": 0.9340175953079178
        },
        "euclidean": {
          "accuracy": 0.6593406593406593,
          "accuracy_threshold": 8.277297973632812,
          "ap": 0.7145362462771898,
          "f1": 0.7070821529745044,
          "f1_threshold": 9.640862464904785,
          "precision": 0.5761772853185596,
          "recall": 0.9149560117302052
        },
        "hf_subset": "sw",
        "languages": [
          "swa-Latn"
        ],
        "main_score": 0.7145362462771898,
        "manhattan": {
          "accuracy": 0.6571428571428571,
          "accuracy_threshold": 184.357666015625,
          "ap": 0.7129454085850159,
          "f1": 0.7086350974930362,
          "f1_threshold": 213.4146728515625,
          "precision": 0.5714285714285714,
          "recall": 0.9325513196480938
        },
        "max": {
          "accuracy": 0.6593406593406593,
          "ap": 0.7145362462771898,
          "f1": 0.7086350974930362
        },
        "similarity": {
          "accuracy": 0.6542124542124542,
          "accuracy_threshold": 0.5331771373748779,
          "ap": 0.7019671473399608,
          "f1": 0.701065619742008,
          "f1_threshold": 0.36831167340278625,
          "precision": 0.5676657584014533,
          "recall": 0.9164222873900293
        }
      }
    ]
  },
  "task_name": "XNLI"
}